{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"upmixing-final\")\n",
    "\n",
    "from unet import UpmixResnet18Scratch\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import librosa\n",
    "from PIL import Image\n",
    "from IPython.display import Video\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR = \"demo\"\n",
    "VIDEO_PATH=\"leftrightdemo3.mp4\"\n",
    "\n",
    "if not os.path.isdir(SAVE_DIR):\n",
    "    os.makedirs(SAVE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in shell: ffmpeg -i leftrightdemo3.mp4 -filter:v fps=fps=30 -strict -2 demo/leftrightdemo3_30fps.mp4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocess video using ffmpeg\n",
    "video_input_path = os.path.splitext(os.path.basename(VIDEO_PATH))[0] + \"_30fps\"\n",
    "video_input_path = os.path.join(SAVE_DIR, video_input_path + \".mp4\")\n",
    "cmd = \"ffmpeg -i %s -filter:v fps=fps=30 -strict -2 %s\" % (VIDEO_PATH, video_input_path)\n",
    "print(\"Running in shell:\", cmd)\n",
    "subprocess.call(cmd, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in shell: ffmpeg -i demo/leftrightdemo3_30fps.mp4 -f mp3 -ab 192000 -vn demo/leftrightdemo3_30fps.mp3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract audio using ffmpeg\n",
    "audio_input_path = os.path.splitext(os.path.basename(video_input_path))[0]\n",
    "audio_input_path = os.path.join(SAVE_DIR, audio_input_path + \".mp3\")\n",
    "cmd = \"ffmpeg -i %s -f mp3 -ab 192000 -vn %s\" % (video_input_path, audio_input_path)\n",
    "print(\"Running in shell:\", cmd)\n",
    "subprocess.call(cmd, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"demo/leftrightdemo3_30fps.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check video\n",
    "Video(video_input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize video clip loader\n",
    "    \n",
    "def load_video(videofile):\n",
    "    capture = cv2.VideoCapture(videofile)\n",
    "    cap_frames = int(capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    v_tensor = []\n",
    "\n",
    "    for idx in range(cap_frames):\n",
    "        ret, frame = capture.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        v_tensor += [frame]\n",
    "\n",
    "    v_tensor = [Image.fromarray(np.uint8(frame)).resize((224,224)) for frame in v_tensor]\n",
    "    v_tensor = np.stack(v_tensor)/255\n",
    "\n",
    "    return v_tensor, cap_frames\n",
    "\n",
    "def load_audio(audiofile):\n",
    "    audio, _ = librosa.load(audiofile, sr=16000, mono=True)\n",
    "    audio = audio/np.max(np.abs(audio))\n",
    "    if len(audio.shape) == 1: # one-channel input\n",
    "        audio = np.stack((audio, audio), axis=0)\n",
    "    return audio\n",
    "\n",
    "class ClipGenerator(object):\n",
    "    def __init__(self, video_fps=30, video_downsample_factor=5, audio_sr=16000, clip_length=2.87, hop_length=2):\n",
    "        self.video_fps = video_fps\n",
    "        self.video_downsample_factor = video_downsample_factor\n",
    "        self.audio_sr = audio_sr\n",
    "        self.clip_length = clip_length\n",
    "        self.hop_length = hop_length\n",
    "\n",
    "        self.n_video_frames = int(video_fps*clip_length)\n",
    "        self.n_audio_samples = int(audio_sr*clip_length)\n",
    "        \n",
    "        self.n_video_frames_hop = int(video_fps*hop_length)\n",
    "        \n",
    "    def generator(self, videofile, audiofile):\n",
    "        video, total_frames = load_video(videofile)\n",
    "        audio = load_audio(audiofile)\n",
    "        \n",
    "        start_idx = 0\n",
    "        \n",
    "        while start_idx < total_frames - self.n_video_frames:\n",
    "            yield self.get_clip(video, audio, start_idx)\n",
    "            start_idx += self.n_video_frames_hop\n",
    "            \n",
    "        yield self.get_clip(video, audio, total_frames - self.n_video_frames, True)\n",
    "            \n",
    "    def get_clip(self, video, audio, start_idx, last_clip=False):\n",
    "        clip = {}\n",
    "        \n",
    "        videoclip = video[start_idx : start_idx+self.n_video_frames : self.video_downsample_factor]\n",
    "        videoclip = torch.from_numpy(videoclip).float()\n",
    "        videoclip = videoclip.permute(3,0,1,2)\n",
    "        \n",
    "        if last_clip:\n",
    "            audio_start_idx = audio.shape[1]-self.n_audio_samples\n",
    "        else:\n",
    "            audio_start_idx = int(start_idx*self.audio_sr/self.video_fps)\n",
    "            \n",
    "        audioclip = audio[:, audio_start_idx : audio_start_idx+self.n_audio_samples]\n",
    "        \n",
    "        audio_sum = audioclip[0] + audioclip[1]\n",
    "        audio_sum_spec = self._get_stft(audio_sum)\n",
    "        audio_sum_spec = torch.from_numpy(audio_sum_spec).float().permute(0,2,1)\n",
    "\n",
    "        audio_diff = audioclip[0] - audioclip[1]\n",
    "        audio_diff_spec = self._get_stft(audio_diff)\n",
    "        audio_diff_spec = torch.from_numpy(audio_diff_spec).float().permute(0,2,1)\n",
    "        \n",
    "        return {'start_frame': start_idx, 'end_frame': start_idx+self.n_video_frames, \n",
    "                'start_audio_frame': audio_start_idx, 'end_audio_frame': audio_start_idx+self.n_audio_samples,\n",
    "                'video': videoclip.unsqueeze(0), 'audio': audioclip, \n",
    "                'audio_sum_spec': audio_sum_spec.unsqueeze(0), 'audio_diff_spec': audio_diff_spec.unsqueeze(0)}\n",
    "\n",
    "    def _get_stft(self, raw):\n",
    "        stft = librosa.core.stft(np.ascontiguousarray(raw), 512, hop_length=160, win_length=400, center=True)\n",
    "        return np.stack((np.real(stft), np.imag(stft)))[:,:-1,:]\n",
    "    \n",
    "    def stft_to_waveform(self, stft):\n",
    "        stft = stft[0,:,:] + (1j * stft[1,:,:])\n",
    "        raw = librosa.core.istft(stft, hop_length=160, win_length=400, center=True)\n",
    "        return raw\n",
    "    \n",
    "clip_generator = ClipGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2D Resnet18 - training weights from scratch\n",
      "loaded pretrained model from models/upmixing-final-exp-1-flip-checkpoint-best.pth.tar\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UpmixResnet18Scratch(\n",
       "  (videonet): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (unet): AudioNet(\n",
       "    (audionet_convlayer1): Sequential(\n",
       "      (0): Conv2d(2, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (audionet_convlayer2): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (audionet_convlayer3): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (audionet_convlayer4): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (audionet_convlayer5): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (audionet_upconvlayer1): Sequential(\n",
       "      (0): ConvTranspose2d(1296, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (audionet_upconvlayer2): Sequential(\n",
       "      (0): ConvTranspose2d(1024, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (audionet_upconvlayer3): Sequential(\n",
       "      (0): ConvTranspose2d(512, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (audionet_upconvlayer4): Sequential(\n",
       "      (0): ConvTranspose2d(256, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (audionet_upconvlayer5): Sequential(\n",
       "      (0): ConvTranspose2d(128, 2, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (1): Tanh()\n",
       "    )\n",
       "    (video_reduction): Sequential(\n",
       "      (0): Conv3d(512, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "      (1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (main_net): ModuleList(\n",
       "    (0): AudioNet(\n",
       "      (audionet_convlayer1): Sequential(\n",
       "        (0): Conv2d(2, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (audionet_convlayer2): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (audionet_convlayer3): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (audionet_convlayer4): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (audionet_convlayer5): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (audionet_upconvlayer1): Sequential(\n",
       "        (0): ConvTranspose2d(1296, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (audionet_upconvlayer2): Sequential(\n",
       "        (0): ConvTranspose2d(1024, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (audionet_upconvlayer3): Sequential(\n",
       "        (0): ConvTranspose2d(512, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (audionet_upconvlayer4): Sequential(\n",
       "        (0): ConvTranspose2d(256, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (audionet_upconvlayer5): Sequential(\n",
       "        (0): ConvTranspose2d(128, 2, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "        (1): Tanh()\n",
       "      )\n",
       "      (video_reduction): Sequential(\n",
       "        (0): Conv3d(512, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (finetune_net): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (4): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (7): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "model = UpmixResnet18Scratch()\n",
    "pretrained = (\"models/upmixing-final-exp-1-flip-checkpoint-best.pth.tar\")\n",
    "avnet = nn.DataParallel(model)\n",
    "checkpoint = torch.load(pretrained)\n",
    "avnet.load_state_dict(checkpoint['state_dict'])\n",
    "print(\"loaded pretrained model from\", pretrained)\n",
    "model = avnet.module\n",
    "model.cuda() # use GPU\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karren/miniconda3/envs/stereolearning/lib/python3.7/site-packages/librosa/core/audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/karren/miniconda3/envs/stereolearning/lib/python3.7/site-packages/librosa/core/audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    }
   ],
   "source": [
    "### upmix audio\n",
    "\n",
    "# load mono audio\n",
    "audio = load_audio(audio_input_path)\n",
    "audio_sum = audio[0] + audio[1]\n",
    "\n",
    "# generate L/R channel difference\n",
    "audio_diff = np.zeros((len(audio_sum),))\n",
    "\n",
    "loader = clip_generator.generator(video_input_path, audio_input_path)\n",
    "for idx, sample in enumerate(loader):\n",
    "    #print(idx)\n",
    "    keys = model.keys + ['audio_diff_spec']\n",
    "    vars = {k: sample[k] for k in keys}\n",
    "    vars = {k: vars[k].cuda() for k in keys}\n",
    "    # debug\n",
    "    #for k, v in vars.items():\n",
    "    #    print(k, v.shape)\n",
    "    out = model(vars)\n",
    "    start_audio_frame = sample['start_audio_frame']\n",
    "    end_audio_frame = sample['end_audio_frame']\n",
    "    \n",
    "    diff = out['pred'].squeeze(0).permute(0,2,1).cpu().data.numpy()\n",
    "    diff = clip_generator.stft_to_waveform(diff)\n",
    "    audio_diff[start_audio_frame:end_audio_frame] = diff\n",
    "    \n",
    "# adjust magnitude of audio diff\n",
    "audio_diff = audio_diff*1.0\n",
    "    \n",
    "audio_pred = np.stack(((audio_sum + audio_diff)/2, (audio_sum - audio_diff)/2))\n",
    "\n",
    "audio_output_path = os.path.splitext(os.path.basename(audio_input_path))[0]\n",
    "audio_output_path = os.path.join(SAVE_DIR, audio_output_path + \"_pred.wav\")\n",
    "librosa.output.write_wav(audio_output_path, np.asfortranarray(audio_pred), sr=16000, norm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine audios with video\n",
    "video_output_path = os.path.splitext(os.path.basename(audio_output_path))[0]\n",
    "video_output_path = os.path.join(SAVE_DIR, video_output_path + \".mp4\")\n",
    "cmd = 'ffmpeg -i %s -i %s -c:v copy -c:a aac -strict experimental -map 0:v:0 -map 1:a:0 %s' % (video_input_path, audio_output_path, video_output_path)\n",
    "subprocess.call(cmd, shell=True)\n",
    "#cmd = 'ffmpeg -i demo/%s.mp4 -i demo/%s_gt.wav -c:v copy -c:a aac -strict experimental -map 0:v:0 -map 1:a:0 demo/output_%s_gt.mp4' % (VIDEO_ID,VIDEO_ID,VIDEO_ID)\n",
    "#subprocess.call(cmd, shell=True)\n",
    "#cmd = 'ffmpeg -i demo/justin_demo_30fps.mov -i demo/justin_demo_30fps_mono.wav -c:v copy -c:a aac -strict experimental -map 0:v:0 -map 1:a:0 demo/justin_demo_30fps_mono.mp4'\n",
    "#subprocess.call(cmd, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"demo/leftrightdemo3_30fps_pred.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check video output\n",
    "Video(video_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
